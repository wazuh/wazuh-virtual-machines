run-name: Wazuh Integration Test - Branch ${{ github.ref_name }} - Launched by @${{ github.actor }}
name: Wazuh VM Test

on:
  workflow_dispatch:
    inputs:
      WAZUH_AUTOMATION_REFERENCE:
        description: 'Branch or tag of the wazuh-automation repository'
        required: true
        default: 'main'
      test_type:
        description: 'Test type'
        required: true
        default: 'ami'
        type: choice
        options:
          - ami
          - ova
      host:
        description: 'AMI ID to create ami or OVA path'
        required: false
        type: string
      WAZUH_SERVER_VERSION_REVISION:
        description: 'Expected Wazuh server version-revision'
        required: false
        type: string
      WAZUH_INDEXER_VERSION_REVISION:
        description: 'Expected Wazuh indexer version-revision'
        required: false
        type: string
      WAZUH_DASHBOARD_VERSION_REVISION:
        description: 'Expected Wazuh dashboard version-revision'
        required: false
        type: string
      TESTS:
        description: 'Test to run'
        required: false
        default: 'ALL'
        type: choice
        options:
          - ALL
          - CERTIFICATES
          - CONNECTIVITY
          - LOGS
          - SERVICE
          - VERSION
          - OVA
      log_level:
        description: 'Log level'
        required: false
        default: 'INFO'
        type: choice
        options:
          - INFO
          - DEBUG
          - TRACE
  pull_request:
    branches:
      - main
    paths:
      - '**.ova'
      - '**.ami'
      - 'packer/**'
      - '.github/workflows/wazuh-vm-test.yml'

env:
  AWS_IAM_OVA_ROLE: ${{ secrets.AWS_IAM_OVA_ROLE }}
  WAZUH_SERVER_EXPECTED_VERSION: ${{ github.event.inputs.WAZUH_SERVER_VERSION_REVISION }}
  WAZUH_INDEXER_EXPECTED_VERSION: ${{ github.event.inputs.WAZUH_INDEXER_VERSION_REVISION }}
  WAZUH_DASHBOARD_EXPECTED_VERSION: ${{ github.event.inputs.WAZUH_DASHBOARD_VERSION_REVISION }}
  WAZUH_AUTOMATION_TOKEN: ${{ secrets.GH_CLONE_TOKEN }}
  WAZUH_AUTOMATION_REFERENCE: ${{ github.event.inputs.WAZUH_AUTOMATION_REFERENCE || 'main' }}

permissions:
  id-token: write
  contents: read
  pull-requests: write

jobs:
  test:
    runs-on: ubuntu-latest

    steps:
      - name: View parameters
        run: echo "${{ toJson(inputs) }}"

      - name: Checkout wazuh-automation repository
        uses: actions/checkout@v4
        with:
          repository: wazuh/wazuh-automation
          ref: ${{ env.WAZUH_AUTOMATION_REFERENCE }}
          token: ${{ secrets.GH_CLONE_TOKEN }}
          path: wazuh-automation

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'
          cache-dependency-path: 'wazuh-automation/integration-test-module/requirements.txt'

      - name: Install dependencies
        run: |
          sudo apt-get update && sudo apt-get install -y git
          python -m pip install --upgrade pip
          pip install -r wazuh-automation/integration-test-module/requirements.txt
          pip install -e wazuh-automation/integration-test-module/

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_IAM_OVA_ROLE }}
          aws-region: us-east-1

      - name: Determine test parameters
        id: test-params
        run: |
          # For workflow_dispatch, use inputs directly
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            echo "test_type=${{ github.event.inputs.test_type }}" >> $GITHUB_OUTPUT
            echo "host=${{ github.event.inputs.host }}" >> $GITHUB_OUTPUT
            echo "test_pattern=${{ github.event.inputs.TESTS }}" >> $GITHUB_OUTPUT
            echo "log_level=${{ github.event.inputs.log_level || 'INFO' }}" >> $GITHUB_OUTPUT
          else
            # For PR events, detect based on changed files or set defaults
            echo "test_type=ami" >> $GITHUB_OUTPUT
            echo "host=" >> $GITHUB_OUTPUT
            echo "test_pattern=ALL" >> $GITHUB_OUTPUT
            echo "log_level=INFO" >> $GITHUB_OUTPUT
          fi

      - name: Run tests with AMI mode
        if: ${{ steps.test-params.outputs.test_type == 'ami' && steps.test-params.outputs.host != '' }}
        run: |
          # Find the test_runner executable
          TEST_RUNNER_PATH=$(find /opt/hostedtoolcache/Python -name "test_runner" | head -n 1)

          # Exit if executable not found
          if [ -z "$TEST_RUNNER_PATH" ]; then
            echo "Error: test_runner executable not found"
            exit 1
          fi

          echo "Found executable at: $TEST_RUNNER_PATH"

          # Run the tests
          $TEST_RUNNER_PATH \
            --test-type ami \
            --ami-id ${{ steps.test-params.outputs.host }} \
            --test-pattern "${{ steps.test-params.outputs.test_pattern }}" \
            --log-level ${{ steps.test-params.outputs.log_level }} \
            --output github \
            --output-file test-results.github

      - name: Run tests with OVA mode
        if: ${{ steps.test-params.outputs.test_type == 'ova' && steps.test-params.outputs.host != '' }}
        run: |
          # Find the test_runner executable
          TEST_RUNNER_PATH=$(find /opt/hostedtoolcache/Python -name "test_runner" | head -n 1)

          # Exit if executable not found
          if [ -z "$TEST_RUNNER_PATH" ]; then
            echo "Error: test_runner executable not found"
            exit 1
          fi

          echo "Found executable at: $TEST_RUNNER_PATH"

          # Run the tests
          $TEST_RUNNER_PATH \
            --test-type ova \
            --ova-s3-path ${{ steps.test-params.outputs.host }} \
            --test-pattern "${{ steps.test-params.outputs.test_pattern }}" \
            --log-level ${{ steps.test-params.outputs.log_level }} \
            --output github \
            --output-file test-results.github

      - name: Parse test results
        if: always()
        id: parse-results
        run: |
          if [ -f test-results.github ]; then
            # Set environment variables from test results file
            while IFS= read -r line; do
              if [[ $line == *=* ]]; then
                echo $line >> $GITHUB_ENV
              fi
            done < test-results.github
          else
            echo "No test results file found!"
            echo "test_status=ERROR" >> $GITHUB_ENV
            echo "total_tests=0" >> $GITHUB_ENV
            echo "passed_tests=0" >> $GITHUB_ENV
            echo "failed_tests=0" >> $GITHUB_ENV
            echo "warning_tests=0" >> $GITHUB_ENV
            echo "skipped_tests=0" >> $GITHUB_ENV
            echo "short_summary=Failed to generate test results" >> $GITHUB_ENV
          fi

      - name: Create GitHub Summary
        if: always()
        run: |
          # Extract multiline summary from the test results
          if [ -f test-results.github ]; then
            awk '/summary<<EOF/{flag=1;next}/EOF/{flag=0}flag' test-results.github > summary.md
            cat summary.md >> $GITHUB_STEP_SUMMARY
          else
            echo "# Test Results" >> $GITHUB_STEP_SUMMARY
            echo "❌ Failed to generate test results" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Comment PR with test results
        if: always() && github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            let summary = '## Wazuh VM Test Results\n\n';

            if (fs.existsSync('summary.md')) {
              summary += fs.readFileSync('summary.md', 'utf8');
            } else {
              summary += '❌ Failed to generate test results';
            }

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summary
            });

      - name: Set job status
        if: always()
        run: |
          if [[ "${{ env.test_status }}" == "PASS" ]]; then
            echo "✅ Tests passed successfully!"
            exit 0
          elif [[ "${{ env.test_status }}" == "WARNING" ]]; then
            echo "⚠️ Tests passed with warnings!"
            exit 0
          else
            echo "❌ Tests failed with status: ${{ env.test_status }}"
            exit 1
          fi
